/home/jccl/p1-roofline/cloudml-project1/env/vmgpu/lib/python3.11/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Traceback (most recent call last):
  File "/home/jccl/p1-roofline/cloudml-project1/code/run_train.py", line 432, in <module>
    raise SystemExit(main())
                     ^^^^^^
  File "/home/jccl/p1-roofline/cloudml-project1/code/run_train.py", line 343, in main
    train_step()
  File "/home/jccl/p1-roofline/cloudml-project1/code/run_train.py", line 335, in train_step
    loss.backward()
  File "/home/jccl/p1-roofline/cloudml-project1/env/vmgpu/lib/python3.11/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/jccl/p1-roofline/cloudml-project1/env/vmgpu/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/jccl/p1-roofline/cloudml-project1/env/vmgpu/lib/python3.11/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility
Command exited with non-zero status 1
	Command being timed: "python code/run_train.py --data data/imagenet-mini --warmup-iters 10 --iters 100 --workers 8 --backend cuda --channels-last --no-augment --deterministic --arch resnet50 --precision fp32 --batch-size 128 --label gcp_resnet50_fp32_bs128_r1"
	User time (seconds): 17.76
	System time (seconds): 3.19
	Percent of CPU this job got: 244%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:08.57
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 1270012
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 676
	Minor (reclaiming a frame) page faults: 747910
	Voluntary context switches: 1186
	Involuntary context switches: 5603
	Swaps: 0
	File system inputs: 176736
	File system outputs: 24
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 1
